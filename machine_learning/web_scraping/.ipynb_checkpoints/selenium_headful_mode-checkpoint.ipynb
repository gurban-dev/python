{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92b52f24-4eba-4976-828b-2d05c833fda9",
   "metadata": {},
   "source": [
    "https://oxylabs.io/blog/selenium-web-scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4bab4d-2bca-4d87-97c2-d6b1398d85a2",
   "metadata": {},
   "source": [
    "Pip is the package manager in the Python programming language.\n",
    "\n",
    "Selenium is the library to install because it automates interacting with web browsers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47c096a0-2091-49f1-a84b-3aa1f0c49447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in /home/linuxbrew/.linuxbrew/opt/python@3.11/lib/python3.11/site-packages (4.29.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in /home/linuxbrew/.linuxbrew/opt/python@3.11/lib/python3.11/site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.2.2)\n",
      "Requirement already satisfied: trio~=0.17 in /home/linuxbrew/.linuxbrew/opt/python@3.11/lib/python3.11/site-packages (from selenium) (0.29.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in /home/linuxbrew/.linuxbrew/opt/python@3.11/lib/python3.11/site-packages (from selenium) (0.12.2)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in /home/linuxbrew/.linuxbrew/opt/python@3.11/lib/python3.11/site-packages (from selenium) (2024.7.4)\n",
      "Requirement already satisfied: typing_extensions~=4.9 in /home/linuxbrew/.linuxbrew/opt/python@3.11/lib/python3.11/site-packages (from selenium) (4.12.2)\n",
      "Requirement already satisfied: websocket-client~=1.8 in /home/linuxbrew/.linuxbrew/opt/python@3.11/lib/python3.11/site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in /home/linuxbrew/.linuxbrew/opt/python@3.11/lib/python3.11/site-packages (from trio~=0.17->selenium) (24.2.0)\n",
      "Requirement already satisfied: sortedcontainers in /home/linuxbrew/.linuxbrew/opt/python@3.11/lib/python3.11/site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in /home/linuxbrew/.linuxbrew/opt/python@3.11/lib/python3.11/site-packages (from trio~=0.17->selenium) (3.7)\n",
      "Requirement already satisfied: outcome in /home/linuxbrew/.linuxbrew/opt/python@3.11/lib/python3.11/site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in /home/linuxbrew/.linuxbrew/opt/python@3.11/lib/python3.11/site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in /home/linuxbrew/.linuxbrew/opt/python@3.11/lib/python3.11/site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /home/linuxbrew/.linuxbrew/opt/python@3.11/lib/python3.11/site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /home/linuxbrew/.linuxbrew/opt/python@3.11/lib/python3.11/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2407d351-5290-432f-9afa-93e99a88948d",
   "metadata": {},
   "source": [
    "Import the webdriver module from the Selenium library, that can it <br>\n",
    "can be taken advantage of to interact with various browsers like <br>\n",
    "Chrome, Firefox, and Safari."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5641320e-8345-4197-82e1-36acef7ec3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c636a10-5718-4130-887f-6f2a7336dad9",
   "metadata": {},
   "source": [
    "From the module selenium.webdriver.common.by, import the class By.\n",
    "\n",
    "This is necessary because the By class makes it feasible to locate elements <br>\n",
    "within the web page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ef274a1-e99e-4b9a-81fe-4df738ad9aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9e7e92-8f43-4b25-92c0-a740214c4875",
   "metadata": {},
   "source": [
    "The ensuing line creates an instance of the Chrome WebDriver.\n",
    "\n",
    "Upon the invocation of webdriver.Chrome(), a new instance of the <br>\n",
    "Google Chrome browser is launched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f352c5f-b029-4c15-b5c9-e6ae67921463",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b29a8ec-5cbb-4ed7-b2c4-324444b100a4",
   "metadata": {},
   "source": [
    "At this point, any page can be loaded in the browser using the get() method.\n",
    "\n",
    "Below, the Chrome browser is given an instruction to navigate to the provided <br>\n",
    "URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42f559c7-d806-4137-8d9f-1fd6e2c1eb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://oxylabs.io/blog')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2ac686-2b2d-468e-b419-de074ac41fc6",
   "metadata": {},
   "source": [
    "The find_elements() method is used to find all elements that match the <br>\n",
    "specified criteria.\n",
    "\n",
    "By.CSS_SELECTOR declares the locator strategy being used. In this case, it <br>\n",
    "indicates that CSS selectors will be used to find element.\n",
    "\n",
    "'a.e1uzm1ya1' targets all anchor tags or `<a>` elements whose class attribute <br>\n",
    "contains the \"e1uzm1ya1\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "943bddfa-c4d6-44b0-b326-ab2c32875d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "blog_titles = driver.find_elements(By.CSS_SELECTOR, 'a.e1uzm1ya1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bc74a2-d8b6-4064-b8f4-aca0bbd69aee",
   "metadata": {},
   "source": [
    "A list of all the matching elements is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a76f1515-60b2-41b0-84e4-8d763fc73928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(blog_titles): <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(f'type(blog_titles): {type(blog_titles)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4c1110-811c-4323-9d2a-e90c99cf44a7",
   "metadata": {},
   "source": [
    "Iterate over the iterable to reveal the elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8b1ae8f-718a-4691-9582-ecb8db3f585c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How to Scrape Google Images With Python\n",
      "Leveraging AI for Large-Scale Scraping and Parsing\n",
      "Web Scraping With cURL Tutorial 2025\n",
      "ISP Proxies vs. Residential Proxies â€“ Ultimate Guide\n",
      "How to Track an IP Address: Find Out Here\n",
      "How to Make a Web Crawler With Python\n",
      "What Is Rate Limiting & How to Avoid It\n",
      "Best Web Scraping Companies in 2025\n",
      "How to Scrape Google News: Step-by-Step Guide\n",
      "Scraping Data from Etsy: A Comprehensive Guide for Data Extraction\n",
      "How to Scrape Walmart in 2025: A Step-by-Step Tutorial\n",
      "10 Best Proxy Providers in 2025\n",
      "How to Scrape Google Maps Using Python\n",
      "9 Playwright Best Practices: Reliable and Easy Tests\n",
      "How to Show HTTP Response Headers in cURL?\n",
      "Running Python on Windows: A Beginner's Guide\n",
      "How to Use cURL in PHP With Examples\n",
      "What is Data Scraping? Complete Guide\n",
      "How to Scrape Indeed Jobs Data in 2025\n"
     ]
    }
   ],
   "source": [
    "for title in blog_titles:\n",
    "    print(title.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9e132e-252d-4987-81ed-eda3204f8c8e",
   "metadata": {},
   "source": [
    "Close the browser instance since leaving it open consume memory and CPU resources. <br>\n",
    "\n",
    "If multiple tests run without closing the browser, it can lead to excessive resource usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18e4f74-44cc-484c-b714-e73d0c3f05f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
